---
title: "An implementation of clustering by \"fast search and find of density peaks\""
author: Thomas Shallcross \& Giovanni Diana
output:
  html_document:
    fig_width: 5
    fig_height: 5

---

## Outline of the algorithm
The outline of the clustering procedure follows the algorithm set out in Rodriguez \& Laio (2014). The basic assumption is that clusters of data points in *n*-dimensional space can be thought of as approximating some arbitrary density distribution. Clusters are defined as areas of high density, and cluster centres are defined as regions of local density maxima, which are sufficiently separate from other maxima.


<center>

```{r, out.width = "75%", echo=FALSE, fig.cap = "Points in *n*-dimensional space can be thought of as approximating some arbitrary density distribution. (left) Points drawn from one of two 2d Gaussian distributions, each of which represents a cluster. (right) The density can be estimated from the data; increases in the density represent clusters and the peaks represent cluster centres"}
knitr::include_graphics("figures/fig1.png")
```
</center>


The clustering procedure aims to find the centre of each cluster i.e. the point of highest density within a cluster. These cluster centres can be thought of as peaks in the density landscape. The number of cluster centres defines the number of clusters. Therefore, unlike many clustering methods, this algorithm has the advantage that the number of clusters are not defined prior to clustering. The way this is achieved is as follows. For each data point, two quantities are calculated:

1. its local density ($\rho_{i}$)
2. its Euclidean distance from the nearest point of higher density ($\delta_i$).

In a slight variation from Rodriguez and Laio (2014), the local density is approximated by calculating the Euclidean distance between point *i* and its $k^{th}$ nearest neighbour ($dKNN$):

\begin{equation}\label{eq:rho}
    \rho_{i}\propto{\frac{1}{[dKNN]^n}}
\end{equation}

where $n$ is equal to the dimensionality of the data. This method of estimating the density can therefore be thought of as asking what is the minimum volume necessary to encapsulate the \textit{k} nearest neighbours of data point \textit{i}.

\noindent{}$\delta_{i}$ is calculated as the minimum distance to any point of higher density, $j$:

\begin{equation}\label{eq:delta}
    \delta_{i} = \min_{j:\rho_{j} > \rho_{i}} (d_{ij})
\end{equation}

The point with highest density is given $\rho_{i} = \max_{j}(d_{ij})$, that is the maximum distance between the highest density point and any other point. Intuitively, it is expected that points of low density tend to be far away from points of higher density simply because there are fewer points close by. Conversely, high density points tend to be close to points of higher density. Therefore, a negative correlation is expected when plotting $\delta$ vs $\rho$. This correlation breaks down, however, when in a local maximum of the density since  it is necessary to travel further than expected to find a point of higher density, at which point we get $\delta_{i}$ much larger than expected, given $\rho_{i}$. These outliers become the cluster centres and define the number of clusters. The remaining points are then assigned to a cluster which is the same as their nearest neighbour of higher density. Using this method, cluster centres are therefore defined as local maxima of the density, sufficiently separated from points with higher densities.

## Implementation

We can run the algorithm on some surrogate data to see how it works.

First we load the data and plot it.

```{r}
source("scripts/DBC_functions.R")
dat <- read.table("data/data.dat")
plot_dat(dat)
```

We can see that the data appears to come from 3 clusters. Our aim is to associate each data point to one of the 3 clusters.

First we calculate the Euclidean distance between all points

```{r}
euc_dist <- as.matrix(dist(dat, upper = T))
```


Next we can calculate the local density of the data ($\rho$). Here we need to choose our parameter, $k$, which defines the nearest neighbour that is used to calculate the density for each point. Larger values of $k$ result in a smoother estimate of the density, whilst a smaller $k$ will pick up small changes in the local density. For now we choose $k = 200$.

```{r}
dens <- calculate_density(euc_dist, KNN = 200)
head(dens, n = 20)
```
If we colour code each point according its estimated density ($\rho$) and plot the data again, we can see that we seem to get a good approximation of the density, where more dense points are purple and sparser points are green.

```{r}
source("scripts/colourscale.R")
cols <- colPalette(dens)
plot(dat, ann = F, xaxt = "n", yaxt = "n", pch = 19, cex = 0.4, col = cols)
```

Next we can estimate the minimum distance to any point of higher density ($\delta$).

```{r}
dis <- calculate_NNHD(euc_dist, dens)
str(dis)
```
The output of this function is a list of length 2. The first element is a vector of the Euclidean distance to each point's nearest neighbour of higher density ($\delta$), and the second element contains a label of which data point is the nearest neighbour of higher density.

We can now plot $log(\delta)$ vs $log(\rho)$.

```{r}
plot_dp(dens, dis$dis)
```

As can be seen in the plot there is a negative correlation between $\delta$ and $\rho$. However, there are three outliers to the right of the dotted line. For these points we have a much higher $\delta$ than expected given $\rho$. This means you have to travel much further than expected to get to a point of higher density. These three points are therefore assigned as cluster centers. The number of cluster centers defines the number of clusters. So in this case, we have 3 clusters. We can find our where our cluster centers are located in our data.

```{r}
cl <- calculate_clusters(dens, dis$dis, dis$NNHD, dat)
str(cl)
```

The output of calculate_clusters is a list of length 2. The first element is a vector of which cluster each point has been assigned to. The second element is a vector of all the cluster centers. We can now plot the data and highlight where the cluster centers are.

```{r}
plot_dat(dat, centers = cl$centers)
```

As can be seen in the plot, the cluster centers are each localised to one of the 3 clusters. We can now plot the data this time colour coding all of the points according to which cluster it has been assigned to.

```{r}
plot_dat(dat, cl = cl$clusters)
```

We have now associated every point to one of the three cluster centers. This is done by assigning a point to the same cluster as its nearest neighbour of higher density. A visual inspection of the plot indicates that the clustering algorithm has worked correctly. However, some of the points around the edge of the clusters, especially those in between the 3 clusters could be considered outliers, i.e those points which don't associate very well to any of the 3 clusters. Rodriguez and Laio provide a framework for removing these clusters.

First, for each data point we look to see if its *$k^{th}$* nearest neighbour is in the same cluster as itself. If not we consider these points as outliers and remove them from the cluster. Second, for each cluster we find the outlier with the highest density and use that a minimum density threshold for that cluster. Any point in that cluster which doesn't meet the minimum density threshold is also removed as an outlier.

To find the outlier we again need to choose a value for $k$. This time $k$ represents how many of a points nearest neighbours need to be in the same cluster as itself for it not to be considered an outlier. Here we have set $k$ to be 5.

```{r}
outlier_thresh <- calculate_outliers(dat, euc_dist, knn =  5, cl$clusters, dens)
plot_dat(dat, cl = cl$clusters, outliers = outlier_thresh)
```

The outliers which have been removed from each cluster are shown as open circles.







